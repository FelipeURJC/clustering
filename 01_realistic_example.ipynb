{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market segmentation\n",
    "\n",
    "Let's work on a realistic scenario. We are going to analyze data from an email marketing campaign. The data can bu found [here](https://blog.minethatdata.com/search/label/MineThatData).\n",
    "\n",
    "This dataset contains 64,000 customers who last purchased within twelve months. The customers were involved in an e-mail test.\n",
    "- 1/3 were randomly chosen to receive an e-mail campaign featuring Mens merchandise.\n",
    "- 1/3 were randomly chosen to receive an e-mail campaign featuring Womens merchandise.\n",
    "- 1/3 were randomly chosen to not receive an e-mail campaign. \n",
    "\n",
    "Customer attributes include:\n",
    "- **Recency**: Months since last purchase.\n",
    "- **History_Segment**: Categorization of dollars spent in the past year.\n",
    "- **History**: Actual dollar value spent in the past year.\n",
    "- **Mens**: 1/0 indicator, 1 = customer purchased Mens merchandise in the past year.\n",
    "- **Womens**: 1/0 indicator, 1 = customer purchased Womens merchandise in the past year.\n",
    "- **Zip_Code**: Classifies zip code as Urban, Suburban, or Rural.\n",
    "- **Newbie**: 1/0 indicator, 1 = New customer in the past twelve months.\n",
    "- **Channel**: Describes the channels the customer purchased from in the past year.\n",
    "- **Segment**: describes the e-mail campaign the customer received\n",
    "    - *Mens E-Mail*: receive an e-mail campaign featuring Mens merchandise\n",
    "    - *Womens E-Mail*: receive an e-mail campaign featuring Womens merchandise\n",
    "    - *No E-Mail*: not receive an e-mail campaign\n",
    "\n",
    "During a period of two weeks following the e-mail campaign, results were tracked:\n",
    "- **Visit**: 1/0 indicator, 1 = Customer visited website in the following two weeks.\n",
    "- **Conversion**: 1/0 indicator, 1 = Customer purchased merchandise in the following two weeks.\n",
    "- **Spend**: Actual dollars spent in the following two week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos fichero\n",
    "marketing_data = pd.read_csv(\"./data/marketing_data.csv\",sep=',') \n",
    "marketing_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have the `history` information, we might want to drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketing_data = marketing_data.drop('history_segment',axis=1)\n",
    "marketing_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Convert categorical variables to numerical ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of categorical variblaes\n",
    "categorical_features = marketing_data.columns[marketing_data.dtypes == 'object'].to_list()\n",
    "\n",
    "# encode data\n",
    "marketing_data_encoded = pd.get_dummies(marketing_data, \n",
    "                                        columns = categorical_features, \n",
    "                                        prefix = 'is', \n",
    "                                        drop_first=True)\n",
    "\n",
    "marketing_data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "cols = ['recency', 'history', 'mens','womens','newbie','visit','conversion','spend',\n",
    "        'is_suburban','is_urban','phone','web','no_email','womens_email']\n",
    "\n",
    "marketing_data_encoded.columns = cols\n",
    "\n",
    "# reordering columnas\n",
    "reordering_cols = ['recency', 'history', 'mens','womens','newbie','is_suburban','is_urban',\n",
    "                   'phone','web','no_email','womens_email','visit','conversion','spend']\n",
    "\n",
    "marketing_data_encoded = marketing_data_encoded[reordering_cols]\n",
    "marketing_data_encoded.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 From pandas to scikit  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# convertimos el DataFrame al formato necesario para scikit-learn\n",
    "data = marketing_data_encoded.values \n",
    "\n",
    "y_visit      = data[:,-3]      \n",
    "y_conversion = data[:,-2]\n",
    "y_spend      = data[:,-1]\n",
    "X = data[:,0:-3]    # nos quedamos con el resto\n",
    "\n",
    "feature_names = marketing_data_encoded.columns[0:-3].to_list()\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "Xs = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Take a look to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#Take a sample and plot it\n",
    "N = 5000\n",
    "random_idx = np.random.choice(Xs.shape[0], N, replace=False)\n",
    "\n",
    "X_tsne = TSNE(n_components=2, random_state=0).fit_transform(Xs[random_idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c = 'b', marker='o', alpha=0.2)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. K-means\n",
    "\n",
    "A possible strategy would be:\n",
    "\n",
    "- Represent `inertia` to determine the number of cluster\n",
    "- Analize the number of samples on each cluster and the sum of distances to the centroid.\n",
    "- For each cluster, `display`  the $n$ closest and the furthest examples from its centroid.\n",
    "- Analyze the features distribution for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "K = range(1,20)\n",
    "\n",
    "inertia = []\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k).fit(Xs)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    \n",
    "plt.plot(K,inertia,'.-')\n",
    "plt.xlabel('# of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "labels_km = kmeans.fit_predict(Xs)\n",
    "\n",
    "print(\"Cluster sizes k-means: {}\".format(np.bincount(labels_km)))\n",
    "\n",
    "distances = []\n",
    "for c in kmeans.cluster_centers_:\n",
    "    d = np.sum( np.sum((Xs - c) ** 2, axis=1) ) \n",
    "    distances.append(d.round(2))\n",
    "    \n",
    "print(\"Cluster distances k-means: {}\".format(distances))\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.bar(range(k),np.bincount(labels_km))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.bar(range(k),distances)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_to_far_from_center(X,centroid, n=5):\n",
    "    \n",
    "    distance = np.sum((X - centroid) ** 2, axis=1)\n",
    "    \n",
    "    print('Close to center')\n",
    "    display(marketing_data_encoded.iloc[np.argsort(distance)[:n]])\n",
    "    \n",
    "    print('Far from center')\n",
    "    display(marketing_data_encoded.iloc[np.argsort(distance)[-n:]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_to_far_from_center(Xs,kmeans.cluster_centers_[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature = 'history'\n",
    "col_number = feature_names.index(feature)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "for l in np.unique(labels_km):\n",
    "    \n",
    "    plt.subplot(2,5,l+1)\n",
    "    plt.hist(X[labels_km == l,col_number],bins = 50, density=True)\n",
    "    plt.xlabel(feature)\n",
    "    plt.title('Cluster #' + str(l))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "for eps in [1, 3, 5, 7]:\n",
    "    print(\"\\neps={}\".format(eps))\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=10)\n",
    "    labels = dbscan.fit_predict(Xs)\n",
    "    print(\"Number of clusters: {}\".format(len(np.unique(labels))))\n",
    "    print(\"Cluster sizes: {}\".format(np.bincount(labels + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some other examples\n",
    "\n",
    "- A. Müller and S. Guido, [Comparing Clustering Algorithms in the Faces Dataset](https://github.com/amueller/introduction_to_ml_with_python/blob/master/03-unsupervised-learning.ipynb).\n",
    "\n",
    "- J. Martínez-Heras, [Clustering Dow Jones stocks](https://github.com/jmartinezheras/2018-MachineLearning-Lectures-ESA/blob/master/5_UnsupervisedLearning/5_Unsupervised_DowJones.ipynb)\n",
    "\n",
    "- P. Mercatoris, [Hierarchical clustering of Exchange-Traded Funds](https://quantdare.com/hierarchical-clustering-of-etfs/)\n",
    "\n",
    "- Google Machine Learning Course [Clustering with Manual Similarity Measure](https://developers.google.com/machine-learning/clustering/programming-exercise)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
